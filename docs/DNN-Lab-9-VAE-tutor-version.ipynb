{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "3bbXhEGl0p"
      },
      "source": [
        "<center><img src='https://drive.google.com/uc?id=1_utx_ZGclmCwNttSe40kYA6VHzNocdET' height=\"60\"></center>\n",
        "\n",
        "AI TECH - Akademia Innowacyjnych Zastosowa\u0144 Technologii Cyfrowych. Program Operacyjny Polska Cyfrowa na lata 2014-2020\n",
        "<hr>\n",
        "\n",
        "<center><img src='https://drive.google.com/uc?id=1BXZ0u3562N_MqCLcekI-Ens77Kk4LpPm'></center>\n",
        "\n",
        "<center>\n",
        "Projekt wsp\u00f3\u0142finansowany ze \u015brodk\u00f3w Unii Europejskiej w ramach Europejskiego Funduszu Rozwoju Regionalnego \n",
        "Program Operacyjny Polska Cyfrowa na lata 2014-2020,\n",
        "O\u015b Priorytetowa nr 3 \"Cyfrowe kompetencje spo\u0142ecze\u0144stwa\" Dzia\u0142anie  nr 3.2 \"Innowacyjne rozwi\u0105zania na rzecz aktywizacji cyfrowej\" \n",
        "Tytu\u0142 projektu:  \u201eAkademia Innowacyjnych Zastosowa\u0144 Technologii Cyfrowych (AI Tech)\u201d\n",
        "    </center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "MjFPoyxoBk"
      },
      "source": [
        "## Variational AutoEncoders\n",
        "\n",
        "In this lab excercise you will train a Variational AutoEncoder to learn the distribution of the MNIST data. You will explore the latent space and learn how to generate new samples. \n",
        "\n",
        "Some notation:\n",
        "* $P^*$ is the true data distribution. We have some samples from this.\n",
        "* $p(z)$ is a *prior* distribution over the latent space. In our model it is multivariate gaussian distribution $N(0,\\mathbb{I})$.\n",
        "* $E(x)$ is the encoder that accepts data points as input and outputs distributions over the latent space $Z$. The produced distribution is denoted $q_\\phi(z|x)$ and is the (approximate) *posterior* distribution. In our model this is mutlivariate gaussian distribution $q_\\phi(z|x) \\sim N(\\mu, diag(\\sigma^2)$. Notes:\n",
        "    1. $\\phi$ are weights of the encoder network.\n",
        "    2. Encoder network accepts data points as input and outputs $\\mu$ and $\\sigma$, which are vectors of the same length as latent space. They are used to construct the approximate posterior distribution $q_\\phi(z|x)$.\n",
        "* $D(z)$ is the decoder that accepts samples from the latent distribution and output parameters of the the likelihood distribution $p_\\theta(x|z)$. In our model this is Bernoulli trial per each pixel $p_\\theta(x|z_0) \\sim Bern(p)$. Notes:\n",
        "    1. $\\theta$ are weights of the decoder network.\n",
        "    2. Decoder network accepts sample from the posterior distribution $q_\\phi(z|x)$ and outputs p, which is a matrix of the shape of the input image. Each value of the matrix is the parameter $\\pi$ of the Bernoulli trial $Bern(\\pi)$ for the corresponding pixel.\n",
        "    3. Data points are clipped to only contain values 0 and 1 so that the model could be trained in the given setup.\n",
        "\n",
        "Loss:\n",
        "The loss that is used is called ELBO (the Evidence Lower Bound).\n",
        "\n",
        "$$ELBO = \\mathbb{E}_{z \\sim q(z|x)} \\big[\\log p_\\theta(x|z)\\big] - \\mathbb{KL}\\big(q_\\phi(z | x) || p(z)\\big).$$\n",
        "\n",
        "The following equation holds:\n",
        "\n",
        "\n",
        "$$\\log p_{\\theta}(x) = ELBO + \\mathbb{KL}(q_\\theta(z|x) || p(z|x))$$\n",
        "\n",
        "Maximization of ELBO is equivalent of minimization of KL-divergence between to variational posterior distribution and the true posterior distribution.\n",
        "\n",
        "The first term of the loss is trained via stochastic gradient descent. The second term can be calculated analytically in our setup and is equal to:\n",
        "\n",
        "$$ \\mathbb{KL}\\big( \\mathcal{N}(\\mu, \\sigma^2) || \\mathcal{N}(0, 1) \\big) = \\frac12 \\big(\\sigma^2  - \\log(\\sigma^2) + \\mu^2 - 1 \\big).$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "eFnuUizAVu"
      },
      "source": [
        "Tasks for the tutorial:\n",
        "1. Run the pipeline and verify that VAE is training and generating decent digit representation.\n",
        "2. Play with training parameters and / or network layers to better learn hidden representation of the data\n",
        "3. Implement sample_latent method in the VariationalAutoEncoder class, which accepts original image as input and outputs samples from the posterior distribution $q_\\phi(z|x)$.\n",
        "4. Implement sample method in the VariationalAutoEncoder class, which accepts sample size and optionally samples from the prior distribution. as input and outputs samples:\n",
        "    1. If samples are not avialable, take a sample $z_0 \\sim p(z)$ from the prior distribution.\n",
        "    2. Decode the latent $p_\\theta(x|z_0) = D_\\theta(z_0)$.\n",
        "    3. Sample a reconstruction from the likelihood: $x_0 \\sim p_\\theta(x|z_0)$.\n",
        "5. Explore the latent space. For each class encode a sample (>=100) of images of that class and take one parameters from the posterior distribution $q_\\phi(z|x)$ per image. Visualize samples as scatter plot. Remeber to color points according to image classes!\n",
        "5. Sample two points $z_0, z_1$ from the prior distibution $p(z)$. Perform interpolation i.e. visualize how samples change based on points from segment ended by $z_0$ and $z_1$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "mIRhZXmXjZ"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms # type: ignore\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from collections import namedtuple\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "o6ghXwN1P4"
      },
      "source": [
        "batch_size = 1024\n",
        "test_batch_size = 1000\n",
        "epochs = 15\n",
        "lr = 5e-3\n",
        "seed = 1\n",
        "log_interval = 5\n",
        "latent_size = 200"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "1fDwZIPWsn"
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "torch.manual_seed(seed)\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "train_kwargs = {'batch_size': batch_size}\n",
        "test_kwargs = {'batch_size': test_batch_size}\n",
        "if use_cuda:\n",
        "    cuda_kwargs = {'num_workers': 1,\n",
        "                    'pin_memory': True,\n",
        "                    'shuffle': True}\n",
        "    train_kwargs.update(cuda_kwargs)\n",
        "    test_kwargs.update(cuda_kwargs)"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
            "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m----> 1\u001b[0m use_cuda \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m use_cuda \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available()\n",
            "\u001b[1;32m      3\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(seed)\n",
            "\u001b[1;32m      4\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_cuda \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "DZ9ksDBfPV"
      },
      "source": [
        "def visualize_data(\n",
        "    images, \n",
        "    labels,\n",
        "    max_images, max_fig_size=(30, 30)):\n",
        "  \n",
        "    num_frames, num_channels, h, w, = images.shape\n",
        "    num_frames = min(num_frames, max_images)\n",
        "    ff, axes = plt.subplots(1, num_frames,\n",
        "                            figsize=max_fig_size,\n",
        "                            subplot_kw={'xticks': [], 'yticks': []})\n",
        "    if num_frames == 1:\n",
        "        axes = [axes]\n",
        "    \n",
        "    for i in range(0, num_frames):\n",
        "        if num_channels == 3:\n",
        "            axes[i].imshow(np.squeeze(images[i]))\n",
        "        else:\n",
        "            axes[i].imshow(np.squeeze(images[i]), cmap='gray')\n",
        "        if labels is not None:\n",
        "            axes[i].set_title(labels[i].item(), fontsize=28)\n",
        "        plt.setp(axes[i].get_xticklabels(), visible=False)\n",
        "        plt.setp(axes[i].get_yticklabels(), visible=False)\n",
        "    ff.subplots_adjust(wspace=0.1)\n",
        "    plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "ed0ibnz7qE"
      },
      "source": [
        "class Binarize:\n",
        "    def __call__(self, sample):\n",
        "        return torch.bernoulli(sample)\n",
        "\n",
        "transform=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    Binarize()\n",
        "])\n",
        "dataset1 = datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transform)\n",
        "dataset2 = datasets.MNIST('../data', train=False,\n",
        "                    transform=transform)\n",
        "train_loader = DataLoader(dataset1,**train_kwargs)\n",
        "test_loader = DataLoader(dataset2, **test_kwargs)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "lXKPRuseLX"
      },
      "source": [
        "real_batch = next(iter(train_loader))\n",
        "visualize_data(real_batch[0], real_batch[1], 8)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "Hs9Xs1J7Tr"
      },
      "source": [
        "EncoderOutput = namedtuple(\"EncoderOutput\", [\"mu\", \"sigma\"])\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(\n",
        "      self,\n",
        "      linear_sizes,\n",
        "      latent_size,\n",
        "      *args,\n",
        "      **kwargs\n",
        "    ):\n",
        "    super().__init__()\n",
        "    self.layers = nn.ModuleList()\n",
        "    for in_layer_size, out_layer_size in zip(linear_sizes, linear_sizes[1:]):\n",
        "        self.layers.append(nn.Linear(in_layer_size, out_layer_size, *args, **kwargs))\n",
        "        self.layers.append(nn.BatchNorm1d(out_layer_size))\n",
        "        self.layers.append(nn.ReLU())\n",
        "    \n",
        "    self.last_layer_mu = nn.Linear(linear_sizes[-1], latent_size)\n",
        "    self.last_layer_sigma = nn.Linear(linear_sizes[-1], latent_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = nn.Flatten()(x)\n",
        "    for layer in self.layers:\n",
        "        x = layer(x)\n",
        "\n",
        "    mu = self.last_layer_mu(x)\n",
        "    logsigma = self.last_layer_sigma(x)\n",
        "    return EncoderOutput(mu, torch.log(1 + torch.exp(logsigma)))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "LHCziTTTb3"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(\n",
        "      self,\n",
        "      linear_sizes,\n",
        "      output_size,\n",
        "      *args,\n",
        "      **kwargs\n",
        "    ):\n",
        "    super().__init__()\n",
        "    self.layers = nn.ModuleList()\n",
        "    for in_layer_size, out_layer_size in zip(linear_sizes, linear_sizes[1:]):\n",
        "        self.layers.append(nn.Linear(in_layer_size, out_layer_size, *args, **kwargs))\n",
        "        self.layers.append(nn.BatchNorm1d(out_layer_size))\n",
        "        self.layers.append(nn.ReLU())\n",
        "    \n",
        "    self.last_layer = nn.Sequential(\n",
        "        nn.Linear(linear_sizes[-1], output_size[0] * output_size[1]),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "    self.output_size = output_size\n",
        "\n",
        "  def forward(self, z):\n",
        "    for layer in self.layers:\n",
        "        z = layer(z)\n",
        "\n",
        "    x = self.last_layer(z)\n",
        "\n",
        "    x = x.view(-1, 1, *self.output_size)\n",
        "    return x"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "wuDJ1QVz4g"
      },
      "source": [
        "VariationalAutoEncoderOutput = namedtuple(\"VariationalAutoEncoderOutput\", [\"mu\", \"sigma\", \"p\"])\n",
        "\n",
        "\n",
        "class VariationalAutoEncoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 encoder_linear_sizes,\n",
        "                 latent_size,\n",
        "                 decoder_linear_sizes,\n",
        "                 output_size):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(encoder_linear_sizes, \n",
        "                               latent_size)\n",
        "        self.decoder = Decoder(decoder_linear_sizes, \n",
        "                               output_size)\n",
        "        self.latent_size = latent_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "\n",
        "        z = torch.normal(0., 1., size=list(encoded.mu.size())).to(device)\n",
        "        z = ( z * encoded.sigma ) + encoded.mu\n",
        "\n",
        "        decoded = self.decoder(z)\n",
        "        return VariationalAutoEncoderOutput(encoded.mu, encoded.sigma, decoded)\n",
        "\n",
        "    def sample_latent(self, x):\n",
        "        # TODO: Task 3.\n",
        "        encoded = self.encoder(x)\n",
        "        z = torch.normal(0., 1., size=list(encoded.mu.size())).to(device)\n",
        "        z = ( z * encoded.sigma ) + encoded.mu   \n",
        "\n",
        "        return z    \n",
        "\n",
        "    def sample(self, sample_size, samples=None):\n",
        "        # TODO: Task 4.\n",
        "        if samples is not None:\n",
        "            samples = torch.normal(0., 1., size=(sample_size, self.latent_size)).to(device)\n",
        "\n",
        "        decoded = self.decoder(samples)\n",
        "        return decoded"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "obLI7tPmnr"
      },
      "source": [
        "def KL_gaussian_loss(mu, sigma):\n",
        "    return torch.mean(((sigma * sigma) - (2 * torch.log(sigma)) + (mu * mu) - 1) / 2)\n",
        "\n",
        "def ELBO(x, p, mu, sigma):\n",
        "    BCE = F.binary_cross_entropy(p, x)\n",
        "    KL = KL_gaussian_loss(mu, sigma)\n",
        "    return BCE + KL"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "AAjUQFvmUO"
      },
      "source": [
        "def train(model: nn.Module, device: torch.device, train_loader: DataLoader,\n",
        "          optimizer: optim.Optimizer, epoch: int, log_interval: int) -> None:\n",
        "    model.train()\n",
        "    for batch_idx, (data, _) in enumerate(train_loader):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = ELBO(data, output.p, output.mu, output.sigma)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "def test(model: nn.Module, device: torch.device, test_loader: DataLoader) -> None:\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, _) in enumerate(test_loader):\n",
        "            data = data.to(device)\n",
        "            output = model(data)\n",
        "            loss = ELBO(data, output.p, output.mu, output.sigma)\n",
        "            test_loss = test_loss + (loss * data.size(0))\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}\\n'.format(test_loss))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "MKcF1ppyPf"
      },
      "source": [
        "vae = VariationalAutoEncoder([28 * 28, 500, 350], latent_size, [200, 350, 500], (28, 28))\n",
        "vae.to(device)\n",
        "optimizer = optim.Adam(vae.parameters(), lr=lr)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "e7KdbmBygw"
      },
      "source": [
        "for epoch in range(1, epochs + 1):\n",
        "    train(vae, device, train_loader, optimizer, epoch, log_interval)\n",
        "    test(vae, device, test_loader)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "RH7wUBm6oj"
      },
      "source": [
        "vae.eval()\n",
        "visualize_data(\n",
        "    vae(real_batch[0].to(device)).p.detach().cpu().numpy(), \n",
        "    labels=real_batch[1].cpu().numpy(), \n",
        "    max_images=8\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "LDPcmBD4KJ"
      },
      "source": [
        "visualize_data(\n",
        "    torch.bernoulli(vae(real_batch[0].to(device)).p).detach().cpu().numpy(), \n",
        "    labels=real_batch[1].cpu().numpy(), \n",
        "    max_images=8\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "pZWX6YQi5T"
      },
      "source": [
        "Visualization of latent space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "rn5obtLmqS"
      },
      "source": [
        "# TODO\n",
        "# Task 5.\n",
        "from sklearn.decomposition import PCA\n",
        "dl = DataLoader(dataset2, batch_size=5000)\n",
        "real_batch = next(iter(dl))\n",
        "samples = vae.sample_latent(real_batch[0].to(device)).detach().cpu().numpy()\n",
        "pca = PCA(2)\n",
        "projections = pca.fit_transform(samples)\n",
        "\n",
        "fig = plt.gcf()\n",
        "ax = plt.gca()\n",
        "fig.set_size_inches(18.5, 10.5)\n",
        "scatter = ax.scatter(projections[:,0], projections[:,1], c=real_batch[1].detach().cpu().numpy())\n",
        "# produce a legend with the unique colors from the scatter\n",
        "legend1 = ax.legend(*scatter.legend_elements(),\n",
        "                    loc=\"lower left\", title=\"Classes\")\n",
        "ax.add_artist(legend1)\n",
        "\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "SFTCNxpj0s"
      },
      "source": [
        "Sample interpolation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "D8W8xnsh8K"
      },
      "source": [
        "#%%capture\n",
        "# TODO\n",
        "# Task 6.\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "grid_size = 100\n",
        "z0 = torch.normal(0,1,size=(1,latent_size))\n",
        "z1 = torch.normal(0,1,size=(1,latent_size))\n",
        "\n",
        "segment = torch.cat([l * z0 + (1-l) * z1 for l in np.linspace(0, 1, grid_size)])\n",
        "\n",
        "images = vae.sample(100, segment).detach().cpu().numpy()\n",
        "fig = plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "ims = [[plt.imshow(np.squeeze(images[i,:]), animated=True)] for i in range(grid_size)]\n",
        "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
        "\n",
        "HTML(ani.to_jshtml())"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "wBbfD2S5S0"
      },
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "python",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}